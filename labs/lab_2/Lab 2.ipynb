{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "import sklearn.linear_model as lm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1 load the titanic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived                                             name     sex  \\\n",
       "0       1         1                    Allen, Miss. Elisabeth Walton  female   \n",
       "1       1         1                   Allison, Master. Hudson Trevor    male   \n",
       "2       1         0                     Allison, Miss. Helen Loraine  female   \n",
       "3       1         0             Allison, Mr. Hudson Joshua Creighton    male   \n",
       "4       1         0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
       "\n",
       "       age  sibsp  parch  ticket      fare    cabin embarked boat   body  \\\n",
       "0  29.0000      0      0   24160  211.3375       B5        S    2    NaN   \n",
       "1   0.9167      1      2  113781  151.5500  C22 C26        S   11    NaN   \n",
       "2   2.0000      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "3  30.0000      1      2  113781  151.5500  C22 C26        S  NaN  135.0   \n",
       "4  25.0000      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "\n",
       "                         home.dest  \n",
       "0                     St Louis, MO  \n",
       "1  Montreal, PQ / Chesterville, ON  \n",
       "2  Montreal, PQ / Chesterville, ON  \n",
       "3  Montreal, PQ / Chesterville, ON  \n",
       "4  Montreal, PQ / Chesterville, ON  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic = pd.read_csv('/Users/jennyli/Google Drive/INFX 574/in class/titanic.csv.bz2')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2 Estimate a LPM model in the form\n",
    "survedi = β0 + β1 · pclassi + β2sexi + εi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>survived</td>     <th>  R-squared:         </th> <td>   0.341</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.340</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   338.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 11 Apr 2018</td> <th>  Prob (F-statistic):</th> <td>4.09e-119</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:17:50</td>     <th>  Log-Likelihood:    </th> <td> -639.31</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1309</td>      <th>  AIC:               </th> <td>   1285.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1306</td>      <th>  BIC:               </th> <td>   1300.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>   <td>    1.0405</td> <td>    0.034</td> <td>   30.888</td> <td> 0.000</td> <td>    0.974</td> <td>    1.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sex[T.male]</th> <td>   -0.5048</td> <td>    0.023</td> <td>  -21.978</td> <td> 0.000</td> <td>   -0.550</td> <td>   -0.460</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pclass</th>      <td>   -0.1453</td> <td>    0.013</td> <td>  -11.066</td> <td> 0.000</td> <td>   -0.171</td> <td>   -0.120</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>60.521</td> <th>  Durbin-Watson:     </th> <td>   1.760</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  68.392</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.560</td> <th>  Prob(JB):          </th> <td>1.41e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.963</td> <th>  Cond. No.          </th> <td>    9.01</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:               survived   R-squared:                       0.341\n",
       "Model:                            OLS   Adj. R-squared:                  0.340\n",
       "Method:                 Least Squares   F-statistic:                     338.3\n",
       "Date:                Wed, 11 Apr 2018   Prob (F-statistic):          4.09e-119\n",
       "Time:                        23:17:50   Log-Likelihood:                -639.31\n",
       "No. Observations:                1309   AIC:                             1285.\n",
       "Df Residuals:                    1306   BIC:                             1300.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "Intercept       1.0405      0.034     30.888      0.000       0.974       1.107\n",
       "sex[T.male]    -0.5048      0.023    -21.978      0.000      -0.550      -0.460\n",
       "pclass         -0.1453      0.013    -11.066      0.000      -0.171      -0.120\n",
       "==============================================================================\n",
       "Omnibus:                       60.521   Durbin-Watson:                   1.760\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               68.392\n",
       "Skew:                           0.560   Prob(JB):                     1.41e-15\n",
       "Kurtosis:                       2.963   Cond. No.                         9.01\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml = smf.ols(formula='survived ~ pclass + sex', data = titanic)\n",
    "r1 = ml.fit()\n",
    "r1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3 Use the model to predict the survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89522742 0.39041749 0.89522742 ... 0.09980047 0.09980047 0.09980047]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a09d615f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict = r1.predict()\n",
    "plt.scatter(titanic.survived, predict)\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Analyze your predicted survival values. What are the maximum and minimum of these? Is any of these equal to 0 or 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min:  0.09980047253428093\n",
      "Max:  0.8952274211186264\n"
     ]
    }
   ],
   "source": [
    "print(\"Min: \", min(predict))\n",
    "print(\"Max: \", max(predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- None of the max and min = 0 -- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5 Now re-compute the survival in the form\n",
    " survived =1(survived >0.5) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.89522742, 0.39041749, 0.89522742, ..., 0.09980047, 0.09980047,\n",
       "       0.09980047])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = [1 if x>0.5 else 0 for x in predict]\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1021"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = np.count_nonzero(predict==titanic['survived'])\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6 Compare the actual and predicted survival rates. What is the accuracy?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7799847211611918"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = [1 if x>0.5 else 0 for x in predict]\n",
    "prediction = np.count_nonzero(predict==titanic['survived'])\n",
    "prediction/len(titanic.survived==1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "77.998% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7 Estimate a similar LPM, but now allow the passenger class effect to differ between men and women.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>survived</td>     <th>  R-squared:         </th> <td>   0.370</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.368</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   153.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 11 Apr 2018</td> <th>  Prob (F-statistic):</th> <td>4.02e-128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:17:50</td>     <th>  Log-Likelihood:    </th> <td> -609.86</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1309</td>      <th>  AIC:               </th> <td>   1232.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1303</td>      <th>  BIC:               </th> <td>   1263.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                 <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                  <td>    0.9653</td> <td>    0.032</td> <td>   29.974</td> <td> 0.000</td> <td>    0.902</td> <td>    1.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(pclass)[T.2]</th>             <td>   -0.0785</td> <td>    0.049</td> <td>   -1.587</td> <td> 0.113</td> <td>   -0.176</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(pclass)[T.3]</th>             <td>   -0.4745</td> <td>    0.042</td> <td>  -11.414</td> <td> 0.000</td> <td>   -0.556</td> <td>   -0.393</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sex[T.male]</th>                <td>   -0.6245</td> <td>    0.043</td> <td>  -14.436</td> <td> 0.000</td> <td>   -0.709</td> <td>   -0.540</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(pclass)[T.2]:sex[T.male]</th> <td>   -0.1161</td> <td>    0.064</td> <td>   -1.801</td> <td> 0.072</td> <td>   -0.243</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(pclass)[T.3]:sex[T.male]</th> <td>    0.2859</td> <td>    0.054</td> <td>    5.340</td> <td> 0.000</td> <td>    0.181</td> <td>    0.391</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>113.251</td> <th>  Durbin-Watson:     </th> <td>   1.746</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 142.526</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.805</td>  <th>  Prob(JB):          </th> <td>1.12e-31</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.136</td>  <th>  Cond. No.          </th> <td>    13.3</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:               survived   R-squared:                       0.370\n",
       "Model:                            OLS   Adj. R-squared:                  0.368\n",
       "Method:                 Least Squares   F-statistic:                     153.2\n",
       "Date:                Wed, 11 Apr 2018   Prob (F-statistic):          4.02e-128\n",
       "Time:                        23:17:50   Log-Likelihood:                -609.86\n",
       "No. Observations:                1309   AIC:                             1232.\n",
       "Df Residuals:                    1303   BIC:                             1263.\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================================\n",
       "                                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------\n",
       "Intercept                      0.9653      0.032     29.974      0.000       0.902       1.028\n",
       "C(pclass)[T.2]                -0.0785      0.049     -1.587      0.113      -0.176       0.019\n",
       "C(pclass)[T.3]                -0.4745      0.042    -11.414      0.000      -0.556      -0.393\n",
       "sex[T.male]                   -0.6245      0.043    -14.436      0.000      -0.709      -0.540\n",
       "C(pclass)[T.2]:sex[T.male]    -0.1161      0.064     -1.801      0.072      -0.243       0.010\n",
       "C(pclass)[T.3]:sex[T.male]     0.2859      0.054      5.340      0.000       0.181       0.391\n",
       "==============================================================================\n",
       "Omnibus:                      113.251   Durbin-Watson:                   1.746\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              142.526\n",
       "Skew:                           0.805   Prob(JB):                     1.12e-31\n",
       "Kurtosis:                       3.136   Cond. No.                         13.3\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2 = smf.ols(formula='survived ~ C(pclass) + sex + C(pclass)*sex', data = titanic)\n",
    "r2 = m2.fit()\n",
    "r2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8 Interpret the coeffcients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class1_female:  0.9653 \n",
      "\n",
      "class2_female:  0.8868 \n",
      "\n",
      "class3_female:  0.49080000000000007 \n",
      "\n",
      "class1_male:  0.3408 \n",
      "\n",
      "class2_male:  0.1462 \n",
      "\n",
      "class3_male:  0.1522 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "intercept = 0.9653 \n",
    "#pclass\n",
    "class1 = 1 \n",
    "class2 = -0.0785\n",
    "class3 = -0.4745\n",
    "\n",
    "#gender\n",
    "female = 1 \n",
    "male = -0.6245\n",
    "\n",
    "# interaction\n",
    "class2_male = -0.1161\n",
    "class3_male = 0.2859\n",
    "\n",
    "print(\"class1_female: \", intercept, \"\\n\")\n",
    "print(\"class2_female: \", intercept + class2, \"\\n\")\n",
    "print(\"class3_female: \", intercept + class3, \"\\n\")\n",
    "print(\"class1_male: \", intercept + male, \"\\n\")\n",
    "print(\"class2_male: \", intercept + class2 + male + class2_male, \"\\n\")\n",
    "print(\"class3_male: \", intercept + class3 + male + class3_male, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, the females from all classes have a very high survival rate. For both genders, the higher class (1>2>3) have a higher survival rate and chance and this could because that the higher the status, the richer the people and therefore they have priority when they are boarding the survival boat. In comparison to male, females have a higher chance for survival and this could be the reason of the lady first culture in general, and female and children are prioritized when escaping from the sinken Titanic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9 Compute the accuracy of your predictions as above. How much did improve by allowing for different gender effects?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96527778 0.34078212 0.96527778 ... 0.15212982 0.15212982 0.15212982]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a0a43ee10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict_new = r2.predict()\n",
    "plt.scatter(titanic.survived, predict_new)\n",
    "print(predict_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7830404889228418"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_new = [1 if x>0.5 else 0 for x in predict_new]\n",
    "prediction_new = np.count_nonzero(predict_new==titanic['survived'])\n",
    "prediction_new/len(titanic.survived==1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "78.3% accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
